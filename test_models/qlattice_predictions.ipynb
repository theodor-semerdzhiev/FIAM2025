{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "BASE_YEARLY_DIR = \"qlattice_yearly\"  # change if needed\n",
    "\n",
    "# ---------- public API ----------\n",
    "def predict_for_year(\n",
    "    df: pd.DataFrame,\n",
    "    test_year: int,\n",
    "    base_yearly_dir: str = \"qlattice_yearly\",\n",
    "    scale_to_validation: bool = True,\n",
    "    return_both: bool = False,\n",
    "    output_col: str = \"stock_ret\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Produce predictions for `df` using the best model of `test_year`.\n",
    "\n",
    "    - Columns with NaNs are NOT dropped; NaNs are replaced with TRAIN means.\n",
    "    - Missing expected feature columns are added and filled with TRAIN means.\n",
    "    - Features are standardized with TRAIN mu/sd (from the saved preproc).\n",
    "    - If `scale_to_validation=True`, outputs are aligned to that year's\n",
    "      validation prediction distribution via z-score mapping.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series of predictions (scaled if enabled) or\n",
    "        pd.DataFrame with columns ['y_pred_raw', 'y_pred_scaled'] if return_both=True.\n",
    "    \"\"\"\n",
    "    # ---------- loader ----------\n",
    "    def load_qlattice_model(model_path: str, preproc_path: Optional[str]) -> Tuple[Any, Dict[str, Any]]:\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        if not preproc_path:\n",
    "            raise FileNotFoundError(\"preproc .npz is required for inference.\")\n",
    "        data = np.load(preproc_path, allow_pickle=True)\n",
    "        preproc = {\n",
    "            \"feat_cols\": data[\"feat_cols\"].tolist(),\n",
    "            \"mu\": np.asarray(data[\"mu\"], dtype=float),\n",
    "            \"sd\": np.asarray(data[\"sd\"], dtype=float),\n",
    "        }\n",
    "        return model, preproc\n",
    "\n",
    "    # ---------- scaling stats ----------\n",
    "    def _load_val_scaling_stats(year_dir: str, year: int) -> Tuple[float, float]:\n",
    "        stats_json = os.path.join(year_dir, f\"qlattice_distribution_stats_{year}.json\")\n",
    "        if os.path.exists(stats_json):\n",
    "            with open(stats_json, \"r\", encoding=\"utf-8\") as f:\n",
    "                d = json.load(f)\n",
    "            return (\n",
    "                float(d[\"val_pred_mean\"]), \n",
    "                float(d[\"val_pred_std\"]), \n",
    "                float(d[\"model_pred_mean\"]), \n",
    "                float(d[\"model_pred_std\"])\n",
    "            )\n",
    "        \n",
    "        raise FileNotFoundError(stats_json)\n",
    "\n",
    "    # ---------- preprocessing ----------\n",
    "    def _ensure_features(df: pd.DataFrame, feat_cols, mu) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Ensure all expected features exist.\n",
    "        - Add any missing columns, filled with the TRAIN mean for that feature.\n",
    "        - Replace NaNs with TRAIN mean, then standardize.\n",
    "        \"\"\"\n",
    "        X = df.reindex(columns=feat_cols, copy=False)\n",
    "        # Add missing columns with mean\n",
    "        miss = [c for c in feat_cols if c not in X.columns]\n",
    "        if miss:\n",
    "            add = pd.DataFrame({c: mu[i] for i, c in enumerate(feat_cols) if c in miss}, index=df.index)\n",
    "            X = pd.concat([X, add], axis=1)\n",
    "            X = X[feat_cols]\n",
    "\n",
    "        # Fill NaNs with TRAIN means (do NOT drop columns)\n",
    "        # Do it vectorized without per-column loops\n",
    "        X = X.astype(float, copy=False)\n",
    "        means_map = {c: float(mu[i]) for i, c in enumerate(feat_cols)}\n",
    "        X = X.fillna(value=means_map)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _standardize_inplace(X: pd.DataFrame, feat_cols, mu, sd) -> None:\n",
    "        # sd guards\n",
    "        sd = np.where(~np.isfinite(sd) | (sd == 0.0), 1.0, sd)\n",
    "        # in-place z-score\n",
    "        for i, c in enumerate(feat_cols):\n",
    "            col = X[c].to_numpy(dtype=float, copy=False)\n",
    "            np.subtract(col, mu[i], out=col)\n",
    "            np.divide(col, sd[i], out=col)\n",
    "            # write back not needed; numpy view writes through\n",
    "\n",
    "    # ---------- model prediction ----------\n",
    "    def _predict_safely(model: Any, X: pd.DataFrame) -> np.ndarray:\n",
    "        # Try X-only first\n",
    "        try:\n",
    "            return np.asarray(model.predict(X), dtype=float)\n",
    "        except Exception:\n",
    "            # Some QLattice models expect [y] + X; feed a dummy y column\n",
    "            tmp = pd.concat([pd.Series(0.0, index=X.index, name=\"__dummy_y__\"), X], axis=1)\n",
    "            return np.asarray(model.predict(tmp), dtype=float)\n",
    "\n",
    "    year_dir = os.path.join(base_yearly_dir, str(test_year))\n",
    "    model_path   = os.path.join(year_dir, f\"qlattice_model_{test_year}.pkl\")\n",
    "    preproc_path = os.path.join(year_dir, f\"qlattice_preproc_{test_year}.npz\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Missing: {model_path}\")\n",
    "    if not os.path.exists(preproc_path):\n",
    "        raise FileNotFoundError(f\"Missing: {preproc_path}\")\n",
    "\n",
    "    model, preproc = load_qlattice_model(model_path, preproc_path)\n",
    "    feat_cols, mu, sd = preproc[\"feat_cols\"], preproc[\"mu\"], preproc[\"sd\"]\n",
    "\n",
    "    # Build X with required features, fill NaNs with TRAIN means, then standardize\n",
    "    X = _ensure_features(df, feat_cols, mu)\n",
    "    _standardize_inplace(X, feat_cols, mu, sd)\n",
    "\n",
    "    # Predict raw\n",
    "    y_raw = _predict_safely(model, X)\n",
    "\n",
    "    if not scale_to_validation:\n",
    "        return pd.Series(y_raw, index=df.index, name=\"y_pred\")\n",
    "\n",
    "    # Align to validation distribution\n",
    "    val_mean, val_std, pred_mean, pred_std = _load_val_scaling_stats(year_dir, test_year)\n",
    "\n",
    "    z = (y_raw - pred_mean) / pred_std\n",
    "    y_scaled = val_mean + z * (val_std if val_std > 0 else 1.0)\n",
    "\n",
    "    if return_both:\n",
    "        return pd.DataFrame(\n",
    "            {f\"{output_col}_raw\": y_raw, f\"{output_col}_scaled\": y_scaled},\n",
    "            index=df.index,\n",
    "        )\n",
    "    else:\n",
    "        return pd.DataFrame(pd.Series(y_scaled, index=df.index, name=output_col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "753743f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/ret_sample.parquet\")\n",
    "df = df[df['year'] == 2017]\n",
    "# Example: run the best 2017 model on some new frame `new_df`\n",
    "# (no target column required; just needs the feature columns it can find)\n",
    "preds = predict_for_year(df, test_year=2018)\n",
    "\n",
    "# If you’d like both the raw and the scaled outputs:\n",
    "both = predict_for_year(df, test_year=2018, return_both=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ddc711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3516737</th>\n",
       "      <td>0.266440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516738</th>\n",
       "      <td>-0.436577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516739</th>\n",
       "      <td>-0.691278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516740</th>\n",
       "      <td>0.503685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516741</th>\n",
       "      <td>-0.193993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828558</th>\n",
       "      <td>-1.298914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828559</th>\n",
       "      <td>-1.305873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828560</th>\n",
       "      <td>-4.744199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828561</th>\n",
       "      <td>0.135690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828562</th>\n",
       "      <td>-1.498913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311826 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_ret\n",
       "3516737   0.266440\n",
       "3516738  -0.436577\n",
       "3516739  -0.691278\n",
       "3516740   0.503685\n",
       "3516741  -0.193993\n",
       "...            ...\n",
       "3828558  -1.298914\n",
       "3828559  -1.305873\n",
       "3828560  -4.744199\n",
       "3828561   0.135690\n",
       "3828562  -1.498913\n",
       "\n",
       "[311826 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701d680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c832ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
