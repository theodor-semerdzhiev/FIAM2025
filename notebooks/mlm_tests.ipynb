{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7688772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models... This may take a moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded. Running tests...\n",
      "\n",
      "==================================================\n",
      "\n",
      "Prompt: The capital of France is <mask>.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  Paris\t(Score: 0.9036)\n",
      "  Token:  Lyon\t(Score: 0.0803)\n",
      "  Token:  Nice\t(Score: 0.0048)\n",
      "  Token:  Nancy\t(Score: 0.0021)\n",
      "  Token:  Napoleon\t(Score: 0.0011)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Paris\t(Score: 0.7924)\n",
      "  Token:  Lyon\t(Score: 0.1572)\n",
      "  Token:  Nancy\t(Score: 0.0190)\n",
      "  Token:  Nice\t(Score: 0.0139)\n",
      "  Token:  Cannes\t(Score: 0.0041)\n",
      "==================================================\n",
      "\n",
      "Prompt: The Toronto Stock Exchange is commonly known as the <mask>.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  TTC\t(Score: 0.4028)\n",
      "  Token:  Exchange\t(Score: 0.1565)\n",
      "  Token:  Toronto\t(Score: 0.1346)\n",
      "  Token:  Index\t(Score: 0.0300)\n",
      "  Token:  index\t(Score: 0.0235)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Exchange\t(Score: 0.1965)\n",
      "  Token:  \"\t(Score: 0.1597)\n",
      "  Token:  Toronto\t(Score: 0.0802)\n",
      "  Token:  Company\t(Score: 0.0487)\n",
      "  Token:  TS\t(Score: 0.0397)\n",
      "==================================================\n",
      "\n",
      "Prompt: For the quarter, our company's net <mask> was $50 million.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  income\t(Score: 0.5362)\n",
      "  Token:  loss\t(Score: 0.3243)\n",
      "  Token:  debt\t(Score: 0.0566)\n",
      "  Token:  revenue\t(Score: 0.0490)\n",
      "  Token:  profit\t(Score: 0.0128)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  income\t(Score: 0.5104)\n",
      "  Token:  loss\t(Score: 0.4496)\n",
      "  Token:  revenue\t(Score: 0.0098)\n",
      "  Token:  earnings\t(Score: 0.0074)\n",
      "  Token:  profit\t(Score: 0.0067)\n",
      "==================================================\n",
      "\n",
      "Prompt: We expect to see high <mask> in the next quarter.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  growth\t(Score: 0.1640)\n",
      "  Token:  volumes\t(Score: 0.0934)\n",
      "  Token:  volatility\t(Score: 0.0721)\n",
      "  Token:  demand\t(Score: 0.0567)\n",
      "  Token:  volume\t(Score: 0.0538)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  volatility\t(Score: 0.1825)\n",
      "  Token:  activity\t(Score: 0.1414)\n",
      "  Token:  demand\t(Score: 0.0992)\n",
      "  Token:  growth\t(Score: 0.0846)\n",
      "  Token:  volumes\t(Score: 0.0830)\n",
      "==================================================\n",
      "\n",
      "Prompt: All public filings are available on <mask>.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  request\t(Score: 0.1254)\n",
      "  Token:  GitHub\t(Score: 0.1123)\n",
      "  Token:  Amazon\t(Score: 0.0870)\n",
      "  Token:  PubMed\t(Score: 0.0821)\n",
      "  Token:  Link\t(Score: 0.0772)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  request\t(Score: 0.3313)\n",
      "  Token:  demand\t(Score: 0.2479)\n",
      "  Token:  GitHub\t(Score: 0.0455)\n",
      "  Token:  consolidation\t(Score: 0.0399)\n",
      "  Token:  Github\t(Score: 0.0340)\n",
      "==================================================\n",
      "\n",
      "Prompt: The <mask> Venture Exchange is home to many mining companies.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  Toronto\t(Score: 0.1979)\n",
      "  Token:  Vancouver\t(Score: 0.1629)\n",
      "  Token:  Joint\t(Score: 0.0647)\n",
      "  Token:  London\t(Score: 0.0641)\n",
      "  Token:  TS\t(Score: 0.0592)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Toronto\t(Score: 0.3829)\n",
      "  Token:  Joint\t(Score: 0.1973)\n",
      "  Token:  London\t(Score: 0.0715)\n",
      "  Token:  TS\t(Score: 0.0670)\n",
      "  Token:  Vancouver\t(Score: 0.0155)\n",
      "==================================================\n",
      "\n",
      "Prompt: The Bank of <mask> sets the overnight interest rate.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  England\t(Score: 0.8827)\n",
      "  Token:  Japan\t(Score: 0.0557)\n",
      "  Token:  Canada\t(Score: 0.0291)\n",
      "  Token:  Australia\t(Score: 0.0251)\n",
      "  Token:  China\t(Score: 0.0008)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Canada\t(Score: 0.8939)\n",
      "  Token:  England\t(Score: 0.0321)\n",
      "  Token:  Japan\t(Score: 0.0180)\n",
      "  Token:  Montreal\t(Score: 0.0146)\n",
      "  Token:  Australia\t(Score: 0.0142)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Canada model\n",
    "\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# --- !! IMPORTANT: SET THIS PATH !! ---\n",
    "# Set this to the path of your *latest* checkpoint\n",
    "# e.g., r'D:\\market_data\\text_data\\CHECKPOINTS\\CANADA-fin-roberta\\checkpoint-4000'\n",
    "YOUR_TRAINED_MODEL_PATH = r'D:\\market_data\\text_data\\CHECKPOINTS\\CANADA-fin-roberta\\checkpoint-4020'\n",
    "\n",
    "# --- Test Sentences ---\n",
    "test_sentences = [\n",
    "    # 1. A test of general knowledge (Did we break it?)\n",
    "    \"The capital of France is <mask>.\",\n",
    "    \n",
    "    # 2. A test of Canadian financial knowledge (The key test)\n",
    "    \"The Toronto Stock Exchange is commonly known as the <mask>.\",\n",
    "    \n",
    "    # 3. A test of financial context\n",
    "    \"For the quarter, our company's net <mask> was $50 million.\",\n",
    "    \n",
    "    # 4. Another financial context test\n",
    "    \"We expect to see high <mask> in the next quarter.\",\n",
    "    \n",
    "    # 5. NEW: Test for Canadian-specific acronyms\n",
    "    \"All public filings are available on <mask>.\",\n",
    "    \n",
    "    # 6. NEW: Test for Canadian-specific institutions\n",
    "    \"The <mask> Venture Exchange is home to many mining companies.\",\n",
    "\n",
    "    # 7. NEW: Test for Canadian-specific institutions\n",
    "    \"The Bank of <mask> sets the overnight interest rate.\"\n",
    "]\n",
    "\n",
    "# --- Script ---\n",
    "\n",
    "def run_test():\n",
    "    if YOUR_TRAINED_MODEL_PATH == r'PLEASE_SET_YOUR_LATEST_CHECKPOINT_PATH':\n",
    "        print(f\"ERROR: Please open '{__file__}' and set the 'YOUR_TRAINED_MODEL_PATH' variable.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(YOUR_TRAINED_MODEL_PATH):\n",
    "        print(f\"ERROR: Path not found: {YOUR_TRAINED_MODEL_PATH}\")\n",
    "        print(\"Please make sure your checkpoint path is correct.\")\n",
    "        return\n",
    "\n",
    "    print(\"Loading models... This may take a moment.\")\n",
    "    \n",
    "    try:\n",
    "        # Load the original, generic roberta-base\n",
    "        base_model = pipeline('fill-mask', model='roberta-base')\n",
    "        \n",
    "        # Load your new, finetuned model from the checkpoint\n",
    "        finetuned_model = pipeline('fill-mask', model=YOUR_TRAINED_MODEL_PATH)\n",
    "        \n",
    "        print(\"Models loaded. Running tests...\\n\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        for sentence in test_sentences:\n",
    "            print(f\"\\nPrompt: {sentence}\")\n",
    "            \n",
    "            # Test Base Model\n",
    "            print(\"\\n--- 1. Base 'roberta-base' Predictions ---\")\n",
    "            base_results = base_model(sentence, top_k=5)\n",
    "            for result in base_results:\n",
    "                print(f\"  Token: {result['token_str']}\\t(Score: {result['score']:.4f})\")\n",
    "                \n",
    "            # Test Finetuned Model\n",
    "            print(\"\\n--- 2. Finetuned Model Predictions ---\")\n",
    "            finetuned_results = finetuned_model(sentence, top_k=5)\n",
    "            for result in finetuned_results:\n",
    "                print(f\"  Token: {result['token_str']}\\t(Score: {result['score']:.4f})\")\n",
    "            \n",
    "            print(\"=\"*50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\")\n",
    "        print(\"This can happen if the model path is wrong or 'transformers' is not installed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457f472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models... This may take a moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded. Running tests...\n",
      "\n",
      "==================================================\n",
      "\n",
      "Prompt: The capital of Japan is <mask>.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  Tokyo\t(Score: 0.8616)\n",
      "  Token:  Kyoto\t(Score: 0.0970)\n",
      "  Token:  Osaka\t(Score: 0.0224)\n",
      "  Token:  Hiroshima\t(Score: 0.0109)\n",
      "  Token:  Kobe\t(Score: 0.0029)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Tokyo\t(Score: 0.8783)\n",
      "  Token:  Kyoto\t(Score: 0.0331)\n",
      "  Token:  yen\t(Score: 0.0170)\n",
      "  Token:  Osaka\t(Score: 0.0149)\n",
      "  Token:  Japan\t(Score: 0.0085)\n",
      "==================================================\n",
      "\n",
      "Prompt: The <mask> is the benchmark index for the Tokyo Stock Exchange.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  benchmark\t(Score: 0.0847)\n",
      "  Token:  yen\t(Score: 0.0635)\n",
      "  Token:  index\t(Score: 0.0549)\n",
      "  Token: IX\t(Score: 0.0546)\n",
      "  Token:  Index\t(Score: 0.0491)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Index\t(Score: 0.2599)\n",
      "  Token:  index\t(Score: 0.1615)\n",
      "  Token:  above\t(Score: 0.1109)\n",
      "  Token:  yen\t(Score: 0.0460)\n",
      "  Token:  benchmark\t(Score: 0.0438)\n",
      "==================================================\n",
      "\n",
      "Prompt: The <mask> Seng Index is the main stock market index in Hong Kong.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  Hang\t(Score: 1.0000)\n",
      "  Token:  Hong\t(Score: 0.0000)\n",
      "  Token:  Kong\t(Score: 0.0000)\n",
      "  Token:  benchmark\t(Score: 0.0000)\n",
      "  Token:  Main\t(Score: 0.0000)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Hang\t(Score: 1.0000)\n",
      "  Token:  Hong\t(Score: 0.0000)\n",
      "  Token:  Hi\t(Score: 0.0000)\n",
      "  Token:  Chi\t(Score: 0.0000)\n",
      "  Token:  benchmark\t(Score: 0.0000)\n",
      "==================================================\n",
      "\n",
      "Prompt: The Shanghai Stock <mask> is a major exchange in mainland China.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  Exchange\t(Score: 0.9955)\n",
      "  Token:  Market\t(Score: 0.0024)\n",
      "  Token:  exchange\t(Score: 0.0007)\n",
      "  Token:  Index\t(Score: 0.0006)\n",
      "  Token: market\t(Score: 0.0001)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Exchange\t(Score: 0.9956)\n",
      "  Token:  Market\t(Score: 0.0034)\n",
      "  Token:  Connect\t(Score: 0.0004)\n",
      "  Token:  Index\t(Score: 0.0002)\n",
      "  Token:  exchange\t(Score: 0.0002)\n",
      "==================================================\n",
      "\n",
      "Prompt: The company's profit for the year was 10 billion <mask>.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  euros\t(Score: 0.8554)\n",
      "  Token:  pounds\t(Score: 0.0887)\n",
      "  Token:  yen\t(Score: 0.0184)\n",
      "  Token:  rand\t(Score: 0.0117)\n",
      "  Token:  yuan\t(Score: 0.0098)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  yuan\t(Score: 0.7307)\n",
      "  Token:  yen\t(Score: 0.1541)\n",
      "  Token:  won\t(Score: 0.1036)\n",
      "  Token:  Yuan\t(Score: 0.0038)\n",
      "  Token:  euros\t(Score: 0.0026)\n",
      "==================================================\n",
      "\n",
      "Prompt: Many tech companies like Samsung are listed on the <mask>.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  exchange\t(Score: 0.2226)\n",
      "  Token:  site\t(Score: 0.1920)\n",
      "  Token:  list\t(Score: 0.1050)\n",
      "  Token:  index\t(Score: 0.0785)\n",
      "  Token:  exchanges\t(Score: 0.0653)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  market\t(Score: 0.4231)\n",
      "  Token:  exchange\t(Score: 0.1220)\n",
      "  Token:  exchanges\t(Score: 0.1039)\n",
      "  Token:  Exchange\t(Score: 0.1026)\n",
      "  Token:  list\t(Score: 0.0436)\n",
      "==================================================\n",
      "\n",
      "Prompt: The <mask> Exchange (SGX) is a key financial hub in Asia.\n",
      "\n",
      "--- 1. Base 'roberta-base' Predictions ---\n",
      "  Token:  Singapore\t(Score: 0.9972)\n",
      "  Token:  Shanghai\t(Score: 0.0013)\n",
      "  Token:  Securities\t(Score: 0.0007)\n",
      "  Token:  Seoul\t(Score: 0.0003)\n",
      "  Token:  Stock\t(Score: 0.0002)\n",
      "\n",
      "--- 2. Finetuned Model Predictions ---\n",
      "  Token:  Singapore\t(Score: 0.9253)\n",
      "  Token:  Stock\t(Score: 0.0678)\n",
      "  Token:  Securities\t(Score: 0.0017)\n",
      "  Token:  Korea\t(Score: 0.0016)\n",
      "  Token:  Korean\t(Score: 0.0007)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Asia Pacific\n",
    "\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# --- !! IMPORTANT: SET THIS PATH !! ---\n",
    "# Set this to the path of your *latest* checkpoint\n",
    "# e.g., r'D:\\market_data\\text_data\\CHECKPOINTS\\CANADA-fin-roberta\\checkpoint-4000'\n",
    "YOUR_TRAINED_MODEL_PATH = r'D:\\market_data\\text_data\\CHECKPOINTS\\ASIA_PACIFIC-fin-roberta\\checkpoint-9600'\n",
    "\n",
    "# --- Test Sentences ---\n",
    "test_sentences = [\n",
    "    # 1. A test of general knowledge (Did we break it?)\n",
    "    \"The capital of Japan is <mask>.\",\n",
    "    \n",
    "    # 2. Test for major exchanges\n",
    "    \"The <mask> is the benchmark index for the Tokyo Stock Exchange.\",\n",
    "    \n",
    "    # 3. Test for major exchanges\n",
    "    \"The <mask> Seng Index is the main stock market index in Hong Kong.\",\n",
    "\n",
    "    # 4. Test for major exchanges\n",
    "    \"The Shanghai Stock <mask> is a major exchange in mainland China.\",\n",
    "    \n",
    "    # 5. Test for financial context (currency)\n",
    "    \"The company's profit for the year was 10 billion <mask>.\",\n",
    "    \n",
    "    # 6. Test for specific country knowledge\n",
    "    \"Many tech companies like Samsung are listed on the <mask>.\",\n",
    "    \n",
    "    # 7. Test for regional context\n",
    "    \"The <mask> Exchange (SGX) is a key financial hub in Asia.\"\n",
    "]\n",
    "\n",
    "# --- Script ---\n",
    "\n",
    "def run_test():\n",
    "    if YOUR_TRAINED_MODEL_PATH == r'PLEASE_SET_YOUR_LATEST_CHECKPOINT_PATH':\n",
    "        print(f\"ERROR: Please open '{__file__}' and set the 'YOUR_TRAINED_MODEL_PATH' variable.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(YOUR_TRAINED_MODEL_PATH):\n",
    "        print(f\"ERROR: Path not found: {YOUR_TRAINED_MODEL_PATH}\")\n",
    "        print(\"Please make sure your checkpoint path is correct.\")\n",
    "        return\n",
    "\n",
    "    print(\"Loading models... This may take a moment.\")\n",
    "    \n",
    "    try:\n",
    "        # Load the original, generic roberta-base\n",
    "        base_model = pipeline('fill-mask', model='roberta-base')\n",
    "        \n",
    "        # Load your new, finetuned model from the checkpoint\n",
    "        finetuned_model = pipeline('fill-mask', model=YOUR_TRAINED_MODEL_PATH)\n",
    "        \n",
    "        print(\"Models loaded. Running tests...\\n\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        for sentence in test_sentences:\n",
    "            print(f\"\\nPrompt: {sentence}\")\n",
    "            \n",
    "            # Test Base Model\n",
    "            print(\"\\n--- 1. Base 'roberta-base' Predictions ---\")\n",
    "            base_results = base_model(sentence, top_k=5)\n",
    "            for result in base_results:\n",
    "                print(f\"  Token: {result['token_str']}\\t(Score: {result['score']:.4f})\")\n",
    "                \n",
    "            # Test Finetuned Model\n",
    "            print(\"\\n--- 2. Finetuned Model Predictions ---\")\n",
    "            finetuned_results = finetuned_model(sentence, top_k=5)\n",
    "            for result in finetuned_results:\n",
    "                print(f\"  Token: {result['token_str']}\\t(Score: {result['score']:.4f})\")\n",
    "            \n",
    "            print(\"=\"*50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\")\n",
    "        print(\"This can happen if the model path is wrong or 'transformers' is not installed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
