{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa87b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c0aaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_10816\\4076849072.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ret_sample_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                       id      date   ret_eom     gvkey  iid excntry  \\\n",
      "0        comp_001081_01C  20050228  20050228    1081.0  01C     CAN   \n",
      "1        comp_001096_01C  20050228  20050228    1096.0  01C     CAN   \n",
      "2         comp_001117_02  20050228  20050228    1117.0   02     USA   \n",
      "3        comp_001166_01W  20050228  20050228    1166.0  01W     NLD   \n",
      "4        comp_001186_01C  20050228  20050228    1186.0  01C     CAN   \n",
      "...                  ...       ...       ...       ...  ...     ...   \n",
      "6401409  comp_367287_01W  20250630  20250630  367287.0  01W     HKG   \n",
      "6401410  comp_367313_01W  20250630  20250630  367313.0  01W     DEU   \n",
      "6401411  comp_367333_01W  20250630  20250630  367333.0  01W     ITA   \n",
      "6401412  comp_367334_01W  20250630  20250630  367334.0  01W     ITA   \n",
      "6401413  comp_367496_01W  20250630  20250630  367496.0  01W     ESP   \n",
      "\n",
      "         stock_ret  year  month  char_date  ...  betadown_252d  \\\n",
      "0        -0.143457  2005      2   20050131  ...       0.779315   \n",
      "1         0.028077  2005      2   20050131  ...       0.445162   \n",
      "2        -0.168627  2005      2   20050131  ...       1.073565   \n",
      "3         0.086271  2005      2   20050131  ...       1.781000   \n",
      "4         0.149056  2005      2   20050131  ...       1.326215   \n",
      "...            ...   ...    ...        ...  ...            ...   \n",
      "6401409  -0.261016  2025      6   20250530  ...            NaN   \n",
      "6401410  -0.573456  2025      6   20250530  ...            NaN   \n",
      "6401411   0.463789  2025      6   20250530  ...            NaN   \n",
      "6401412  -0.215849  2025      6   20250530  ...            NaN   \n",
      "6401413   0.048849  2025      6   20250530  ...            NaN   \n",
      "\n",
      "         prc_highprc_252d  corr_1260d  betabab_1260d  rmax5_rvol_21d  age  \\\n",
      "0                0.672204    0.387781       0.845865        0.805580  541   \n",
      "1                0.937664    0.245148       0.456872        0.923214  517   \n",
      "2                0.708333    0.124188       0.863334        0.898113  373   \n",
      "3                0.676545    0.560895       1.560202        1.342814  289   \n",
      "4                0.774557    0.174888       0.399060        0.777183  385   \n",
      "...                   ...         ...            ...             ...  ...   \n",
      "6401409               NaN         NaN            NaN             NaN   41   \n",
      "6401410               NaN         NaN            NaN             NaN   29   \n",
      "6401411               NaN         NaN            NaN             NaN   29   \n",
      "6401412               NaN         NaN            NaN             NaN    5   \n",
      "6401413               NaN         NaN            NaN             NaN  497   \n",
      "\n",
      "              qmj  qmj_prof  qmj_growth  qmj_safety  \n",
      "0       -1.508294 -0.994164   -0.832048   -1.017248  \n",
      "1       -0.706080 -0.247574   -0.155802   -0.485635  \n",
      "2        1.344458  1.601108    1.612067   -0.566631  \n",
      "3       -1.355529 -0.904719   -0.999531   -1.231687  \n",
      "4        1.123762  0.154734    1.196690    0.939661  \n",
      "...           ...       ...         ...         ...  \n",
      "6401409       NaN       NaN         NaN         NaN  \n",
      "6401410       NaN       NaN         NaN         NaN  \n",
      "6401411       NaN       NaN         NaN         NaN  \n",
      "6401412       NaN       NaN         NaN         NaN  \n",
      "6401413 -1.017309 -1.281802   -0.724235    0.048676  \n",
      "\n",
      "[6401414 rows x 159 columns]>\n"
     ]
    }
   ],
   "source": [
    "ret_sample_path = r'C:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\data\\ret_sample.csv'\n",
    "\n",
    "df = pd.read_csv(ret_sample_path)\n",
    "\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e73c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the memory-efficient script to split data by company ID.\n",
      "Created output directory: C:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\data\\csv_by_id\n",
      "Reading data from C:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\data\\ret_sample.csv in chunks of 500000 rows...\n",
      "--- Processing Chunk 1 ---\n",
      "Extracting and cleaning IDs...\n",
      "Grouping by ID and saving to files...\n",
      "Chunk 1 processed successfully.\n",
      "Unique IDs found so far: 20599\n",
      "--- Processing Chunk 2 ---\n",
      "Extracting and cleaning IDs...\n",
      "Grouping by ID and saving to files...\n",
      "Chunk 2 processed successfully.\n",
      "Unique IDs found so far: 23736\n",
      "--- Processing Chunk 3 ---\n",
      "Extracting and cleaning IDs...\n",
      "Grouping by ID and saving to files...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    101\u001b[39m output_folder_name = \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m_Files\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mPersonal\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mProjects\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mFIAM\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mFIAM2025\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcsv_by_id\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# 3. Run the main function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mprocess_csv_in_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mprocess_csv_in_chunks\u001b[39m\u001b[34m(input_csv_path, output_dir, chunk_size)\u001b[39m\n\u001b[32m     76\u001b[39m         created_files.add(output_path) \u001b[38;5;66;03m# Mark this file as created\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         \u001b[43mgroup_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m processed successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Add a running counter after each chunk is processed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\myenv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\myenv\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\myenv\\Lib\\site-packages\\pandas\\io\\common.py:615\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    607\u001b[39m \u001b[33;03mCheck if parent directory of a file exists, raise OSError if it does not\u001b[39;00m\n\u001b[32m    608\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    612\u001b[39m \u001b[33;03m    Path to check parent directory of\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_abc.py:465\u001b[39m, in \u001b[36mPathBase.is_dir\u001b[39m\u001b[34m(self, follow_symlinks)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03mWhether this path is a directory.\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m S_ISDIR(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m.st_mode)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_local.py:515\u001b[39m, in \u001b[36mPath.stat\u001b[39m\u001b[34m(self, follow_symlinks)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, follow_symlinks=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    511\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[33;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    os.stat() does.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_csv_in_chunks(input_csv_path, output_dir, chunk_size=1000000):\n",
    "    \"\"\"\n",
    "    Reads and processes a large CSV in chunks to avoid memory errors. It\n",
    "    uses the 'gvkey' column to save separate CSV files for each unique ID.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): The path to the input CSV file.\n",
    "        output_dir (str): The directory where the output CSVs will be saved.\n",
    "        chunk_size (int): The number of rows to process in each chunk.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "    # This set will keep track of which files we have already written the header for\n",
    "    created_files = set()\n",
    "    \n",
    "    try:\n",
    "        print(f\"Reading data from {input_csv_path} in chunks of {chunk_size} rows...\")\n",
    "        \n",
    "        # Use the 'chunksize' parameter to create an iterator\n",
    "        chunk_iterator = pd.read_csv(input_csv_path, low_memory=False, chunksize=chunk_size)\n",
    "        \n",
    "        # Loop through each chunk (a smaller DataFrame) from the file\n",
    "        for i, chunk in enumerate(chunk_iterator):\n",
    "            print(f\"--- Processing Chunk {i+1} ---\")\n",
    "\n",
    "            # --- ID Transformation using 'gvkey' column ---\n",
    "            print(\"Cleaning 'gvkey' column and preparing for grouping...\")\n",
    "            # Drop rows where gvkey is missing\n",
    "            chunk.dropna(subset=['gvkey'], inplace=True)\n",
    "            # Convert gvkey to integer type to remove decimals (e.g., 1081.0 -> 1081)\n",
    "            chunk['gvkey'] = chunk['gvkey'].astype(int)\n",
    "            \n",
    "            # --- Append rows to the correct files ---\n",
    "            print(\"Grouping by 'gvkey' and saving to files...\")\n",
    "            # Group the current chunk by the integer 'gvkey'\n",
    "            grouped_chunk = chunk.groupby('gvkey')\n",
    "            \n",
    "            # Loop through each unique ID found in this chunk\n",
    "            for current_id, group_df in grouped_chunk:\n",
    "                file_name = f\"{current_id}.csv\"\n",
    "                output_path = os.path.join(output_dir, file_name)\n",
    "                \n",
    "                # If we haven't created this file yet, write with a header.\n",
    "                # Otherwise, append without the header.\n",
    "                if output_path not in created_files:\n",
    "                    group_df.to_csv(output_path, index=False, mode='w', header=True)\n",
    "                    created_files.add(output_path) # Mark this file as created\n",
    "                else:\n",
    "                    group_df.to_csv(output_path, index=False, mode='a', header=False)\n",
    "            \n",
    "            print(f\"Chunk {i+1} processed successfully.\")\n",
    "            # Add a running counter after each chunk is processed\n",
    "            print(f\"Unique IDs found so far: {len(created_files)}\")\n",
    "\n",
    "        print(\"\\nProcessing complete. All chunks have been processed and files saved.\")\n",
    "        # Add a final count at the end of the script\n",
    "        print(f\"Total unique IDs found and files created: {len(created_files)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_csv_path}' was not found. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# --- How to use this script ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting the memory-efficient script to split data by company ID.\")\n",
    "    \n",
    "    # 1. Set the path to your input CSV file.\n",
    "    input_file_path = r'C:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\data\\ret_sample.csv'\n",
    "    \n",
    "    # 2. Set the path for the output folder.\n",
    "    output_folder_name = r'C:\\_Files\\Personal\\Projects\\FIAM\\FIAM2025\\data\\csv_by_id'\n",
    "    \n",
    "    # 3. Run the main function.\n",
    "    process_csv_in_chunks(input_file_path, output_folder_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
